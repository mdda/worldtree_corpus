{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, Dict, Tuple, Set, Union\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate=False\n",
    "statements = dataset.load_statements(regenerate=regenerate)\n",
    "statements_by_uid = { s.uid:s for s in statements }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../tg2020task/tableindex.txt\", \"rt\") as f:\n",
    "    table_names:List[str] = ['Q', 'A-right', 'A-wrong', ]  \n",
    "    table_names += [ l.strip().replace('.tsv', '') for l in f ]\n",
    "name_to_table_idx:Dict[str,int] = { n:i for i,n in enumerate(table_names) }\n",
    "table_names[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qanda = [] # Gather all question\n",
    "for fold in 'train|dev|test'.split('|'):\n",
    "    # Train set has 1 question without explanations: Mercury_7221305\n",
    "    qanda += [qa for qa in dataset.load_qanda(fold, regenerate=regenerate)\n",
    "               if fold=='test' or len(qa.explanation_gold)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(BaseModel):\n",
    "    id:Union[str, dataset.UID]\n",
    "    is_statement:bool=False\n",
    "    is_question:bool =False; n_q:int=0\n",
    "    is_ansY:bool     =False\n",
    "    is_ansN:bool     =False\n",
    "    raw_txt:str\n",
    "    keywords:dataset.Keywords\n",
    "    table_idx:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes:List[Node] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in statements:\n",
    "    graph_nodes.append( Node(id=s.uid, is_statement=True,\n",
    "                             keywords=s.keywords, raw_txt=s.raw_txt, \n",
    "                             table_idx=name_to_table_idx[s.table], ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qa in qanda:\n",
    "    graph_nodes.append( Node(id=qa.question_id, is_question=True, n_q=len(qa.answers),\n",
    "                             keywords=qa.question.keywords, raw_txt=qa.question.raw_txt, \n",
    "                             table_idx=name_to_table_idx['Q'], ) )\n",
    "    for i,ans in enumerate(qa.answers):\n",
    "        graph_nodes.append( Node(id=f\"{qa.question_id}_A{i}\", \n",
    "                                 is_ansY=(i==0), is_ansN=(i>0),\n",
    "                                 keywords=ans.keywords, raw_txt=ans.raw_txt, \n",
    "                                  table_idx=name_to_table_idx['A-right' if i==0 else 'A-wrong'], ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(graph_nodes):,}\") # 33,872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a big list of keyword->node, so we can then do edges from that\n",
    "kw_to_graph_idx = defaultdict(list)\n",
    "for idx, node in enumerate(graph_nodes):\n",
    "    for kw in node.keywords:\n",
    "        kw_to_graph_idx[kw].append(idx)\n",
    "print(len(kw_to_graph_idx)) # 6540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kw, arr in kw_to_graph_idx.items():\n",
    "    if len(arr)>500: \n",
    "        print(kw, len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_edges=[]\n",
    "for kw, arr in kw_to_graph_idx.items():\n",
    "    for i in arr:\n",
    "        for j in arr:\n",
    "            if i==j:continue\n",
    "            graph_edges.append( (i,j) )\n",
    "print(f\"{len(graph_edges):,}\") # 34,527,162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate links\n",
    "graph_edges = list(set(graph_edges)) # Fixed order\n",
    "print(f\"n_edges={len(graph_edges):,}  \"+\n",
    "      f\"edge_fraction={len(graph_edges)/len(graph_nodes)/len(graph_nodes)*100.:.2f}%\")\n",
    "# n_edges=31,695,592, edge_fraction=2.76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True, floatmode='fixed', sign=' ')\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK_MAX=512\n",
    "#BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "# This will be updated for each different question/prediction input\n",
    "#   and will be the .x values\n",
    "ranker = torch.tensor( [ [0.] for n in graph_nodes ], dtype=torch.float)\n",
    "\n",
    "# This is auxilliary data (embeddings, etc)\n",
    "tables = torch.tensor( [ [n.table_idx] for n in graph_nodes ], dtype=torch.long)\n",
    "\n",
    "#edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "#                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "#edge_index = torch.tensor([\n",
    "#    [ pair[0] for pair in graph_edges],\n",
    "#    [ pair[1] for pair in graph_edges],\n",
    "#], dtype=torch.long)\n",
    "edge_index_t = torch.tensor(graph_edges, dtype=torch.long)  \n",
    "\n",
    "graph_data = Data(x=ranker, tables=tables, \n",
    "                  edge_index=edge_index_t.t().contiguous()) # Like suggested in the intro docs\n",
    "                  #edge_index=edge_index)\n",
    "graph_data.num_nodes, graph_data.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
