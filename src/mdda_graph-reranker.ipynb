{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, Dict, Tuple, Set, Union\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate=False\n",
    "statements = dataset.load_statements(regenerate=regenerate)\n",
    "statements_by_uid = { s.uid:s for s in statements }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../tg2020task/tableindex.txt\", \"rt\") as f:\n",
    "    table_names:List[str] = ['Q', 'A-right', 'A-wrong', ]  \n",
    "    table_names += [ l.strip().replace('.tsv', '') for l in f ]\n",
    "name_to_table_idx:Dict[str,int] = { n:i for i,n in enumerate(table_names) }\n",
    "table_names[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qanda = [] # Gather all question\n",
    "for fold in 'train|dev|test'.split('|'):\n",
    "    # Train set has 1 question without explanations: Mercury_7221305\n",
    "    qanda += [qa for qa in dataset.load_qanda(fold, regenerate=regenerate)\n",
    "               if fold=='test' or len(qa.explanation_gold)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(BaseModel):\n",
    "    id:Union[str, dataset.UID]\n",
    "    is_statement:bool=False\n",
    "    is_question:bool =False; n_ans:int=0\n",
    "    is_ansY:bool     =False\n",
    "    is_ansN:bool     =False\n",
    "    raw_txt:str\n",
    "    keywords:dataset.Keywords\n",
    "    table_idx:int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes:List[Node] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements_existing=set()\n",
    "for s in statements:\n",
    "    if not len(s.uid)==19: continue # Only do base statements (not combos)  FIXME\n",
    "    if not s.uid in statements_existing:\n",
    "        graph_nodes.append( Node(id=s.uid, is_statement=True,\n",
    "                                 keywords=s.keywords, raw_txt=s.raw_txt, \n",
    "                                 table_idx=name_to_table_idx[s.table], ) )\n",
    "        statements_existing.add(s.uid)\n",
    "    else:\n",
    "        print(f\"Duplicate statement ignored : {s.uid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qa in qanda:\n",
    "    graph_nodes.append( Node(id=qa.question_id, is_question=True, n_ans=len(qa.answers),\n",
    "                             keywords=qa.question.keywords, raw_txt=qa.question.raw_txt, \n",
    "                             table_idx=name_to_table_idx['Q'], ) )\n",
    "    for i,ans in enumerate(qa.answers):\n",
    "        graph_nodes.append( Node(id=f\"{qa.question_id}_A{i}\", \n",
    "                                 is_ansY=(i==0), is_ansN=(i>0),\n",
    "                                 keywords=ans.keywords, raw_txt=ans.raw_txt, \n",
    "                                 table_idx=name_to_table_idx['A-right' if i==0 else 'A-wrong'], ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups=defaultdict(int)\n",
    "for i,n in enumerate(graph_nodes):\n",
    "    dups[n.id]+=1\n",
    "[ k for k,v in dups.items() if v>1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form a quick look-up from statment/question/answer id to node indes\n",
    "id_to_graph_node_idx = { n.id:i for i,n in enumerate(graph_nodes) } \n",
    "\n",
    "print(f\"{len(graph_nodes):,} == {len(id_to_graph_node_idx):,}\") # 33,872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a big list of keyword->node, so we can then do edges from that\n",
    "kw_to_graph_idx = defaultdict(list)\n",
    "for idx, node in enumerate(graph_nodes):\n",
    "    for kw in node.keywords:\n",
    "        kw_to_graph_idx[kw].append(idx)\n",
    "print(len(kw_to_graph_idx)) # 6540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kw, arr in kw_to_graph_idx.items():\n",
    "    if len(arr)>500: \n",
    "        print(kw, len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_edges=[]\n",
    "for kw, arr in kw_to_graph_idx.items():\n",
    "    for i in arr:\n",
    "        for j in arr:\n",
    "            if i==j:continue\n",
    "            graph_edges.append( (i,j) )\n",
    "print(f\"{len(graph_edges):,}\") # 34,518,168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate links\n",
    "graph_edges = list(set(graph_edges)) # Fixed order\n",
    "print(f\"n_edges={len(graph_edges):,}  \"+\n",
    "      f\"edge_fraction={len(graph_edges)/len(graph_nodes)/len(graph_nodes)*100.:.2f}%\")\n",
    "# n_edges=31,687,626  edge_fraction=2.76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True, floatmode='fixed', sign=' ')\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK_MAX=512\n",
    "#BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "# This will be updated for each different question/prediction input\n",
    "#   and will be the .x values\n",
    "ranker = torch.tensor( [ [0.] for n in graph_nodes ], dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "# This is auxilliary data (embeddings, etc)\n",
    "table_idx = torch.tensor( [ [n.table_idx] for n in graph_nodes ], dtype=torch.long, requires_grad=False)\n",
    "bools     = torch.tensor( [ [n.is_statement, n.is_question, n.is_ansY, n.is_ansN, ] \n",
    "                            for n in graph_nodes ], dtype=torch.int32, requires_grad=False)\n",
    "\n",
    "#edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "#                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "#edge_index = torch.tensor([\n",
    "#    [ pair[0] for pair in graph_edges],\n",
    "#    [ pair[1] for pair in graph_edges],\n",
    "#], dtype=torch.long)\n",
    "edge_index_t = torch.tensor(graph_edges, dtype=torch.long)  \n",
    "\n",
    "graph_data = Data(x=ranker, table_idx=table_idx, bools=bools, \n",
    "                  edge_index=edge_index_t.t().contiguous()) # Like suggested in the intro docs\n",
    "                  #edge_index=edge_index)\n",
    "graph_data.num_nodes, graph_data.num_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "graph_data = graph_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RerankGraphDataset(Dataset):\n",
    "    def __init__(self, fold='dev', preds_file='../predictions/predict.FOLD.baseline-retrieval.txt',\n",
    "                ):\n",
    "        self.fold  = fold\n",
    "        \n",
    "        regenerate=False\n",
    "        # Train set has 1 question without explanations: Mercury_7221305\n",
    "        self.qanda = [qa for qa in dataset.load_qanda(fold, regenerate=regenerate)\n",
    "                         if fold=='test' or len(qa.explanation_gold)>0]\n",
    "        \n",
    "        # Load up prediction set\n",
    "        preds=defaultdict(list) # qa_id -> [statements in order]\n",
    "        with open(preds_file.replace('FOLD', self.fold), 'rt') as f:\n",
    "            for l in f.readlines():\n",
    "                qid, uid = l.strip().split('\\t')\n",
    "                #if qid not in preds: preds[qid]=[]\n",
    "                preds[qid].append(uid)\n",
    "        self.preds=preds\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.qanda)\n",
    "\n",
    "    def __getitem__(self, idx):  # This corresponds to a specific question\n",
    "        qa = self.qanda[idx]\n",
    "        q_id=qa.question_id\n",
    "        \n",
    "        pred = self.preds[q_id][:RANK_MAX]\n",
    "        pred_uid_to_idx = { uid:i for i, uid in enumerate(pred) }  # Needed for explanation_gold\n",
    "        \n",
    "        # Want to return a list of nodes in graph_data be retained\n",
    "        #   Can calculate edges using\n",
    "        #     https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.subgraph\n",
    "            \n",
    "        # And return corresponding 'x' and 'y' values for each of these slots too\n",
    "        \n",
    "        n_ans = graph_nodes[id_to_graph_node_idx[q_id]].n_ans  # This must be a question...\n",
    "        if n_ans<=0:\n",
    "            print(f\"Question not found : {q_id}\")\n",
    "            n_ans=0\n",
    "\n",
    "        n_nodes  = RANK_MAX+1+n_ans\n",
    "        node_idx = np.zeros( (n_nodes,), dtype=np.int32 )    # These are the nodes of interest\n",
    "        ranker   = np.zeros( (n_nodes,), dtype=np.float32 )  # This is the previous output\n",
    "        labels   = np.zeros( (n_nodes,), dtype=np.float32 )  # This is the {0,1} target  (BCE likes floats)\n",
    "        \n",
    "        for i,uid in enumerate(pred):  # For all the predictions\n",
    "            node_idx[i]= id_to_graph_node_idx[uid]\n",
    "            ranker[i]  = 1.0 - (float(i)/RANK_MAX)\n",
    "        \n",
    "        # Here's the question\n",
    "        node_idx[RANK_MAX] = id_to_graph_node_idx[q_id]\n",
    "        # And the answers\n",
    "        for a in range(n_ans):\n",
    "            node_idx[RANK_MAX+1+a] = id_to_graph_node_idx[f\"{q_id}_A{a}\"]\n",
    "        \n",
    "        for ex in qa.explanation_gold:\n",
    "            if ex.uid in pred_uid_to_idx:  # These are in same positions as node_idx\n",
    "                labels[ pred_uid_to_idx[ex.uid] ] = 1.\n",
    "        #if labels.sum()==0.: labels[0]=1. # Prevent NAN if nothing is 1 for APLoss...\n",
    "        \n",
    "        return dict( idx=idx, q_id=qa.question_id,\n",
    "                        node_idx = node_idx, \n",
    "                        ranker = ranker,\n",
    "                        labels = labels,\n",
    "                    )\n",
    "\n",
    "ds_dev=RerankGraphDataset(fold='dev')    \n",
    "#ds_dev[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net_GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_Simple, self).__init__()\n",
    "        #self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        #self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        \n",
    "        table_emb_size, hidden_size=8, 64\n",
    "        self.table_embedding = torch.nn.Embedding(len(table_names), table_emb_size)        \n",
    "        \n",
    "        # ranker, table.embedding, bools\n",
    "        n_features = 1+table_emb_size+4\n",
    "        \n",
    "        self.conv1 = GCNConv(n_features, hidden_size)\n",
    "        self.conv2 = GCNConv(hidden_size, 1)\n",
    "        self.output = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.bx_loss = torch.nn.BCELoss()\n",
    "\n",
    "    #def forward(self, ranker, table_idx, bools, edge_index):\n",
    "    def forward(self, data, edge_index):\n",
    "        #x, edge_index = data.x, data.edge_index\n",
    "        ranker, table_idx, bools = data.x, data.table_idx, data.bools\n",
    "        #print(f\"ranker.size() : {ranker.size()}\")        # torch.Size([517])\n",
    "        #print(f\"table_idx.size() : {table_idx.size()}\")  # table_idx.size() : torch.Size([517, 1])\n",
    "        #print(f\"bools.size() : {bools.size()}\")          # bools.size() : torch.Size([517, 4])\n",
    "\n",
    "        x_table_emb = self.table_embedding(table_idx)\n",
    "        #print(f\"x_table_emb.size() : {x_table_emb.size()}\")  # x_table_emb.size() : torch.Size([517, 1, 8])\n",
    "        \n",
    "        x = torch.cat( [ranker.unsqueeze(-1), x_table_emb.squeeze(1), bools], axis=-1)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.conv import GATConv\n",
    "from torch_geometric.nn.conv import GatedGraphConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        table_emb_size, hidden_size=8, 64\n",
    "        self.table_embedding = torch.nn.Embedding(len(table_names), table_emb_size)        \n",
    "        \n",
    "        # ranker, table.embedding, bools\n",
    "        n_features = 1+table_emb_size+4\n",
    "        \n",
    "        #self.conv1 = GCNConv(n_features, hidden_size)\n",
    "        #self.conv2 = GCNConv(hidden_size, 1)\n",
    "        \n",
    "        # As long as n_features<hidden_size, this will just be padded out...\n",
    "        self.gru = GatedGraphConv(hidden_size, num_layers=4, aggr='max')\n",
    "\n",
    "        self.conv1 = GATConv(hidden_size, hidden_size//8, heads=8, )  # dropout=0.6\n",
    "        self.conv2 = GATConv(hidden_size, 1, heads=1, concat=False, ) # dropout=0.6\n",
    "\n",
    "        self.output = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.bx_loss = torch.nn.BCELoss()\n",
    "\n",
    "    def forward(self, data, edge_index):\n",
    "        ranker, table_idx, bools = data.x, data.table_idx, data.bools\n",
    "        x_table_emb = self.table_embedding(table_idx)\n",
    "        x = torch.cat( [ranker.unsqueeze(-1), x_table_emb.squeeze(1), bools], axis=-1)\n",
    "        \n",
    "        x = self.gru(x, edge_index)\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        #x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "#list(model.parameters())\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "\n",
    "def make_subgraph(d):\n",
    "    subset = torch.tensor(d['node_idx'], dtype=torch.long).to(device)\n",
    "    edge_index_subset, _ = torch_geometric.utils.subgraph(subset, graph_data.edge_index, relabel_nodes=True)\n",
    "    #print(edge_index.type(), edge_index.shape ) # torch.cuda.LongTensor torch.Size([2, 39206])\n",
    "    \n",
    "    ranker    = torch.tensor(d['ranker'], requires_grad=False).to(device)\n",
    "    table_idx = graph_data.table_idx[subset]  # This becomes 'relabelled' in the same way\n",
    "    bools     = graph_data.bools[subset]      # This becomes 'relabelled' in the same way\n",
    "\n",
    "    labels    = torch.tensor(d['labels'], requires_grad=False).to(device)\n",
    "\n",
    "    return Data(x=ranker, table_idx=table_idx, bools=bools, \n",
    "                #edge_index=edge_index_subset, \n",
    "                y=labels), edge_index_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def run_training(d, steps=10):\n",
    "    subgraph, edge_index_subgraph = make_subgraph(d)\n",
    "    for step in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        #ranks_pred = model(ranker, table_idx, bools, edge_index)\n",
    "        ranks_pred = model(subgraph, edge_index_subgraph)\n",
    "        \n",
    "        #loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss = model.bx_loss(ranks_pred, subgraph.y.unsqueeze(-1))\n",
    "        #print(i, loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #break\n",
    "    return loss.item()  # Final loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    loss_tot, loss_cnt=0., 0\n",
    "    for i in tqdm(range(len(ds_dev)), desc=f\"epoch[{epoch}]\"):\n",
    "        d = ds_dev[i]\n",
    "        loss=run_training(d, steps=10)\n",
    "        loss_tot+=loss\n",
    "        loss_cnt+=1\n",
    "    print(f\"epoch[{epoch}] : loss_bx.mean()={loss_tot/loss_cnt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
