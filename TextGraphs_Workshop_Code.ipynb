{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCm7H7jfPEJ7"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "!pip install -q fire\n",
    "!git clone -q https://github.com/mdda/worldtree_corpus.git\n",
    "!cd worldtree_corpus/ && git checkout textgraphs && git pull\n",
    "!cp -a worldtree_corpus/textgraphs .\n",
    "\n",
    "# Setup data\n",
    "path_data = Path(\"worldtree_corpus_textgraphs2019sharedtask_withgraphvis\")\n",
    "!wget -q -nc http://cognitiveai.org/dist/{path_data}.zip\n",
    "!unzip -qn {path_data}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "colab_type": "code",
    "id": "B9JTdvnLP9uK",
    "outputId": "60680518-ee1e-4326-9c95-fff69497f2d2"
   },
   "outputs": [],
   "source": [
    "# Run OptimizedTFIDF method on dev set\n",
    "!python textgraphs/run_ranking.py \\\n",
    "--path_data={path_data} \\\n",
    "--recurse_tfidf=False \\\n",
    "--do_train=False \\\n",
    "--do_dev=True \\\n",
    "--do_test=False \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "colab_type": "code",
    "id": "QWlpU_C2QUcM",
    "outputId": "4aa1950f-80b6-450c-9571-4e071142ec96"
   },
   "outputs": [],
   "source": [
    "# Run IterativeTFIDF method on dev set\n",
    "!python textgraphs/run_ranking.py \\\n",
    "--path_data={path_data} \\\n",
    "--recurse_tfidf=True \\\n",
    "--do_train=False \\\n",
    "--do_dev=True \\\n",
    "--do_test=False \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJHFp-EqWvhZ"
   },
   "source": [
    "###Setup for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "id": "UJBcxFZqVcDN",
    "outputId": "3a112655-fd0a-4573-d39f-a5d7d70acf4b"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
    "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "print('TPU address is', TPU_ADDRESS)\n",
    "DELETE_EXISTING_MODEL = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "with tf.Session(TPU_ADDRESS) as session:\n",
    "  print('TPU devices:')\n",
    "  pprint.pprint(session.list_devices())\n",
    "\n",
    "  # Upload credentials to TPU.\n",
    "  with open('/content/adc.json', 'r') as f:\n",
    "    auth_info = json.load(f)\n",
    "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
    "  # Now credentials are set for all future sessions on this TPU.\n",
    "    \n",
    "    \n",
    "!test -d bert_repo || git clone https://github.com/chiayewken/bert bert_repo\n",
    "!cd bert_repo && git pull\n",
    "\n",
    "# STS-B dataset is always needed as a reference for data format\n",
    "!test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
    "!python download_glue_repo/download_glue_data.py --data_dir='glue_data' --tasks=STS\n",
    "    \n",
    "TASK = \"textgraphs\" #@param [\"textgraphs\", \"STS-B\", \"MNLI\"]\n",
    "glue_tasks = {'MNLI', 'MRPC', 'CoLA', 'STS-B'}\n",
    "\n",
    "if TASK in glue_tasks:\n",
    "    # Download glue data.\n",
    "    _task = TASK.split(\"-\")[0]  # STS-B -> STS\n",
    "    !python download_glue_repo/download_glue_data.py --data_dir='glue_data' --tasks=$_task\n",
    "\n",
    "    TASK_DATA_DIR = 'glue_data/' + TASK\n",
    "    print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
    "    !ls $TASK_DATA_DIR\n",
    "else:\n",
    "    print(\"Warning: custom task\")\n",
    "    TASK_DATA_DIR = None\n",
    "\n",
    "BUCKET = 'YOUR_BUCKET' #@param {type:\"string\"}\n",
    "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
    "OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}_regressor_{}'.format(BUCKET, TASK, True)\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
    "\n",
    "# Available pretrained model checkpoints:\n",
    "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
    "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
    "#   cased_L-12_H-768_A-12: cased BERT large model\n",
    "BERT_MODEL = \"uncased_L-12_H-768_A-12\" #@param [\"uncased_L-12_H-768_A-12\", \"uncased_L-24_H-1024_A-16\"]\n",
    "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "zpCGH329Wj6r",
    "outputId": "764277f9-b2ee-452f-8665-5b22f4b86b35"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"bert_repo\")\n",
    "# import run_scorer\n",
    "import run_regressor as run_scorer\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def read_tsv(file, first_line_header=True):\n",
    "    lines = run_scorer.DataProcessor._read_tsv(file)\n",
    "    if first_line_header:\n",
    "        df = pd.DataFrame(lines[1:], columns=lines[0])\n",
    "    else:\n",
    "        df = pd.DataFrame(lines)\n",
    "    return df\n",
    "\n",
    "def write_tsv(df, file):\n",
    "    df.to_csv(file, sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "def write_data(texts_a, texts_b, scores, file, reference_file=\"glue_data/STS-B/train.tsv\"):\n",
    "    assert len(texts_a) == len(texts_b) == len(scores)\n",
    "    dummy = [None] * len(scores)\n",
    "    ref_columns = read_tsv(reference_file).columns\n",
    "    data = {\n",
    "        \"index\": list(range(len(scores))),\n",
    "        \"sentence1\": texts_a,\n",
    "        \"sentence2\": texts_b,\n",
    "        \"score\": scores,\n",
    "    }\n",
    "    assert all([col in ref_columns for col in list(data.keys())])\n",
    "    \n",
    "    data_list = [(data.get(col) or dummy) for col in ref_columns]\n",
    "    df = pd.DataFrame(zip(*data_list), columns=ref_columns)\n",
    "    print(df.shape)\n",
    "    assert all([a == b for a, b in zip(ref_columns, df.columns)])\n",
    "    write_tsv(df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "5XJ3rWhnWm62",
    "outputId": "d43532a7-3cb7-41ae-b0dc-af2e77894084"
   },
   "outputs": [],
   "source": [
    "# Setup task specific model and TPU running config.\n",
    "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL \n",
    "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
    "!gsutil ls $BERT_PRETRAINED_DIR\n",
    "\n",
    "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
    "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
    "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
    "\n",
    "OUTPUT_DIR = OUTPUT_DIR.replace('bert-tfhub', 'bert-checkpoints')\n",
    "if DELETE_EXISTING_MODEL:\n",
    "    if tf.io.gfile.exists(OUTPUT_DIR):  # Delete and reset model_dir every time\n",
    "        tf.io.gfile.rmtree(OUTPUT_DIR)\n",
    "    tf.io.gfile.mkdir(OUTPUT_DIR)\n",
    "!gsutil ls $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jymxsY97dCys"
   },
   "source": [
    "###Train BERT and do re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "82FyOYbnXYmm",
    "outputId": "ec05e53d-d36f-4bb7-8e24-79447e7baef7"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run IterativeTFIDF method on train/eval to generate data for BERT\n",
    "!python textgraphs/run_ranking.py \\\n",
    "--path_data={path_data} \\\n",
    "--recurse_tfidf=True \\\n",
    "--do_train=True \\\n",
    "--do_dev=True \\\n",
    "--do_test=False \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "zB4fMX9zXone",
    "outputId": "60fa0e67-de43-4575-a0f0-910e206688a5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def write_textgraph_scores_data(df_scores, out_file):\n",
    "    write_data(\n",
    "        texts_a=df_scores.text_q.tolist(),\n",
    "        texts_b=df_scores.text_e.tolist(),\n",
    "        scores=df_scores.score.tolist(),\n",
    "        file=out_file,\n",
    "    )\n",
    "!rm -rf data\n",
    "!mkdir data\n",
    "!cp df_scores_dev.csv df_scores_test.csv\n",
    "for mode in [\"train\", \"dev\", \"test\"]:\n",
    "    write_textgraph_scores_data(pd.read_csv(f\"df_scores_{mode}.csv\"), f\"data/{mode}.tsv\")\n",
    "!ls -lh data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6UCKbV9_XuOb",
    "outputId": "f23d12db-8c59-4a60-ae8c-f6b2094f9e7a"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save snapshot of codebase for reproducibility\n",
    "!zip -qr bert_repo.zip bert_repo\n",
    "!zip -qr textgraphs.zip textgraphs\n",
    "!gsutil cp textgraphs.zip bert_repo.zip {OUTPUT_DIR}\n",
    "\n",
    "!python bert_repo/run_regressor.py \\\n",
    "--task_name=STS-B \\\n",
    "--data_dir=data \\\n",
    "--bert_config_file=$CONFIG_FILE \\\n",
    "--output_dir=$OUTPUT_DIR \\\n",
    "--vocab_file=$VOCAB_FILE \\\n",
    "--do_train=True \\\n",
    "--do_eval=False \\\n",
    "--do_predict=True \\\n",
    "--use_tpu=True \\\n",
    "--tpu_name=$TPU_ADDRESS \\\n",
    "--eval_batch_size=32 \\\n",
    "--predict_batch_size=32 \\\n",
    "--save_checkpoints_steps=99999 \\\n",
    "--init_checkpoint=$BERT_PRETRAINED_DIR/bert_model.ckpt \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "id": "VKuSj99dad0R",
    "outputId": "b88ffc22-6a32-4576-db6f-4039892f5359"
   },
   "outputs": [],
   "source": [
    "# BERT Re-ranking and re-scoring\n",
    "!python textgraphs/run_ranking.py \\\n",
    "--path_data={path_data} \\\n",
    "--do_train=False \\\n",
    "--do_dev=True \\\n",
    "--do_test=False \\\n",
    "--bert_output_dir={OUTPUT_DIR} \\"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "rJHFp-EqWvhZ",
    "jymxsY97dCys"
   ],
   "name": "TextGraphs Workshop Code.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
